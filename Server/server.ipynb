{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAção Server\n",
    "\n",
    "This notebook implements the ReAção emotion detection server. The server works with two threads, the first responsible for interacting with the final application, and the second for reading the camera and detecting emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import json\n",
    "import select\n",
    "import threading\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms \n",
    "from torch.autograd import Variable\n",
    "\n",
    "import sys\n",
    "emonet_path = \"D:\\\\Github\\\\emonet\" # Change for your emonet repository path\n",
    "sys.path.append(emonet_path)\n",
    "from emonet.models import EmoNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_sever = False #If should stop the server thread\n",
    "stop_detector = False #If should stop the detector thread\n",
    "\n",
    "emotion_data = {\"valence\": 0.0, \"arousal\":0.0, \"meanValence\":0.0, \"meanArousal\":0.0} #Emotion info\n",
    "tracking = False #If should track the emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Change the address, port and camera index as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"127.0.0.1\"\n",
    "PORT = 65444\n",
    "capture_device_index = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server function\n",
    "\n",
    "The server function creates the connection with the client, get tracking info and send emotion data in JSON format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python38\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Python38\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-57-bcc9b33f07d3>\", line 35, in server_func\n",
      "ConnectionResetError: [WinError 10054] Foi forçado o cancelamento de uma conexão existente pelo host remoto\n"
     ]
    }
   ],
   "source": [
    "def server_func():\n",
    "    global tracking, stop_sever, emotion_data\n",
    "    tracking = False\n",
    "    \n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.bind((HOST, PORT))\n",
    "\n",
    "    s.listen()\n",
    "    conn = None\n",
    "\n",
    "    #Create connection\n",
    "    while conn is None:\n",
    "        if stop_sever:\n",
    "            s.close()\n",
    "            return\n",
    "\n",
    "        readable, _, _ = select.select([s], [], [], 0)\n",
    "\n",
    "        for rconn in readable:\n",
    "            if rconn is s:\n",
    "                conn, addr = s.accept()\n",
    "                break\n",
    "\n",
    "    #Get and send data\n",
    "    while True:\n",
    "        if stop_sever:\n",
    "            conn.close()\n",
    "            s.close()\n",
    "            return\n",
    "\n",
    "        rconn, _, _ = select.select([conn], [], [], 0)\n",
    "\n",
    "        if tracking:\n",
    "            data = json.dumps(emotion_data).encode(\"UTF-8\")\n",
    "            conn.sendall(data)\n",
    "\n",
    "        if len(rconn) != 0:\n",
    "            message = rconn[0].recv(1024)\n",
    "            message = message.decode(\"utf-8\")\n",
    "            \n",
    "            if message == \"false\":\n",
    "                tracking = False\n",
    "                data = json.dumps(emotion_data).encode(\"UTF-8\")\n",
    "                conn.sendall(data)\n",
    "            else:\n",
    "                tracking = True\n",
    "\n",
    "            print(\"Tracking:\", tracking)\n",
    "    \n",
    "\n",
    "server_thread = threading.Thread(target=server_func, daemon=True)\n",
    "server_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector\n",
    "\n",
    "For the detector side, first the model is loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model constants\n",
    "\n",
    "torch.backends.cudnn.benchmark =  True\n",
    "n_expression = 8\n",
    "device = 'cuda:0'\n",
    "image_size = 256\n",
    "expression_dict = {0: 'neutral', 1:'happy', 2:'sad', 3:'surprise', 4:'fear', 5:'disgust', 6:'anger', 7:'contempt', 8:'none'}\n",
    "state_dict_path = emonet_path+\"\\\\pretrained\\\\emonet_8.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model preprocessing\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                                        transforms.Resize((256,256)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "state_dict = torch.load(str(state_dict_path), map_location='cpu')\n",
    "state_dict = {k.replace('module.',''):v for k,v in state_dict.items()}\n",
    "net = EmoNet(n_expression=n_expression).to(device)\n",
    "net.load_state_dict(state_dict, strict=False)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the detector function gets the camera frame and saves the detected emotion in the global dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector_func():\n",
    "    global tracking, stop_detector, emotion_data\n",
    "    #tracking = False\n",
    "    \n",
    "    cap = cv.VideoCapture(capture_device_index)\n",
    "    ret, frane = cap.read()\n",
    "\n",
    "    valence_hist = deque(maxlen=60)\n",
    "    arousal_hist = deque(maxlen=60)\n",
    "\n",
    "\n",
    "    while cap.isOpened():\n",
    "        if stop_detector:\n",
    "            cap.release()\n",
    "            return\n",
    "        if not tracking:\n",
    "            if len(valence_hist) != 0:\n",
    "                valence_hist.clear()\n",
    "                arousal_hist.clear()\n",
    "\n",
    "            continue\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Camera stream end\")\n",
    "            break\n",
    "\n",
    "\n",
    "        frameRGB = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(frameRGB)\n",
    "\n",
    "        image_tensor = test_transforms(image).float()\n",
    "        image_tensor = image_tensor.unsqueeze(0)\n",
    "\n",
    "        imgInput = Variable(image_tensor)\n",
    "        imgInput = imgInput.to(device)\n",
    "\n",
    "        output = net(imgInput)\n",
    "\n",
    "        valence = output[\"valence\"]\n",
    "        valence = valence.cpu().detach().numpy()\n",
    "        valence = valence[0]\n",
    "\n",
    "        arousal = output[\"arousal\"]\n",
    "        arousal = arousal.cpu().detach().numpy()\n",
    "        arousal = arousal[0]\n",
    "\n",
    "        #heatmap = output['heatmap']\n",
    "        #heatmap = heatmap.cpu().detach().numpy()\n",
    "\n",
    "        #expression = output['expression']\n",
    "        #expression = expression.cpu().detach().numpy()\n",
    "        #expression = np.argmax(np.squeeze(expression), axis=0)\n",
    "        #expression = expression_dict[expression]\n",
    "\n",
    "        valence_hist.append(valence)\n",
    "        arousal_hist.append(arousal)\n",
    "\n",
    "        emotion_data[\"valence\"] = float(valence)\n",
    "        emotion_data[\"arousal\"] = float(arousal)\n",
    "        emotion_data[\"meanArousal\"] = float(np.mean(valence_hist))\n",
    "        emotion_data[\"meanValence\"] = float(np.mean(arousal_hist))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "detector_thread = threading.Thread(target=detector_func, daemon=True)\n",
    "detector_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring\n",
    "\n",
    "The following cell can be useful to monitor if the threads are still working: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server thread is dead\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    stop = False\n",
    "\n",
    "    if not detector_thread.is_alive():\n",
    "        print(\"Detector thread is dead\")\n",
    "        stop = True\n",
    "        \n",
    "    if not server_thread.is_alive():\n",
    "        print(\"Server thread is dead\")\n",
    "        stop = True\n",
    "    \n",
    "    if stop:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the stop variables to stop some thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_detector = False\n",
    "stop_sever = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_sever = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
